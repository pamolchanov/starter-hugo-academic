---
# Display name
# title: Pavlo Molchanov

# Is this the primary user of the site?
superuser: true

# Role/position/tagline
# role: Distinguished Research Scientist and Manager

# Organizations/Affiliations to show in About widget
# organizations:
#   - name: NVIDIA Research
#     url: https://www.nvidia.com/en-us/research/

# Short bio (displayed in user profile at end of posts)
bio: Working on efficient deep learning and human centric computer vision.

# Interests to show in About widget
#interests:
#  - Machine Learning, compression, adaptive models
#  - Computer Vision, pose estimation, model inversion


# Education to show in About widget
#education:
#  courses:
#    - course: PhD in Signal Processing
#      institution: Tampere University, Finland
#      year: 2014
#    - course: MEng in Radio Systems
#      institution: National Aerospace University, Kharkiv, Ukraine
#      year: 2010

# Social/Academic Networking
# For available icons, see: https://wowchemy.com/docs/getting-started/page-builder/#icons
#   For an email link, use "fas" icon pack, "envelope" icon, and a link in the
#   form "mailto:your-email@example.com" or "/#contact" for contact widget.
social:
  - icon: envelopes-bulk
    icon_pack: fas
    link: 'mailto:pmolchanov_at_nvidia.com'
  - icon: envelope
    icon_pack: fas
    link: 'mailto:pamolchanov_at_gmail.com'
  - icon: twitter
    icon_pack: fab
    link: https://twitter.com/PavloMolchanov
  - icon: graduation-cap # Alternatively, use `google-scholar` icon from `ai` icon pack
    icon_pack: fas
    link: https://scholar.google.com/citations?user=J9PoyoIAAAAJ&hl=en&oi=ao
  - icon: linkedin
    icon_pack: fab
    link: https://www.linkedin.com/in/pavlo-molchanov-08738a63/

# Link to a PDF of your resume/CV.
# To use: copy your resume to `static/uploads/resume.pdf`, enable `ai` icons in `params.toml`,
# and uncomment the lines below.
# - icon: cv
#   icon_pack: ai
#   link: uploads/resume.pdf

# Enter email to display Gravatar (if Gravatar enabled in Config)
# email: 'pmolchanov -at- nvidia.com'
email: 'pamolchanov -at- gmail.com'

# Highlight the author in author lists? (true/false)
highlight_name: true
---
<!-- I am a distinguished research scientist and team manager with [NVIDIA Research](https://www.nvidia.com/en-us/research/) since 2015. My research is focused on efficient deep learning and human-centric computer vision in LPR team lead by [Jan Kautz](https://jankautz.com). Since 2023, I am leading a research team on efficient deep learning with the focus on model compression, NAS like acceleration, novel architectures, and adaptive/conditional inference.
 <!-- In the area of human-centric vision I am working on face/body/hand landmarks and pose estimation, action/gesture recognition and designing novel human-computer interaction systems.  -->

<!-- I obtained PhD from Tampere University of Technology, Finland in the area of signal processing in 2014 supervised by [Karen Eguiazarian](https://www.tuni.fi/en/karen-eguiazarian). I received my master degree from National Aerospace University, Kharkiv, Ukraine in Radio Systems focusing on high-order spectrum techniques for signal processing and mentored by [Alexander Totsky](https://ieeexplore.ieee.org/author/37391220000). -->
<!-- # My dissertation was focused on designing automatic target recognition systems for radars and general radar signal processing. During PhD studies I was honored to receive EuRAD best paper award in 2011 and EuRAD young engineer award in 2013. -->

<!-- We always look for promising interns and full time positions, feel free to ping me for details. I am also interested in connecting with people who share similar research interests.  -->

<!-- I am a Distinguished Research Scientist and Team Manager at [NVIDIA Research](https://www.nvidia.com/en-us/research/). I work in the LPR team led by [Jan Kautz](https://jankautz.com), focusing on efficient deep learning and human-centric computer vision. Since 2023, I have been leading a research team dedicated to efficient deep learning, specifically in the areas of model compression, NAS-like acceleration, novel architectures, and adaptive/conditional inference. Currently we are primary focused on LLM and vision-language models. 

I earned my PhD from Tampere University of Technology, Finland in 2014, specializing in signal processing under the supervision of [Karen Eguiazarian](https://www.tuni.fi/en/karen-eguiazarian). Prior to that, I obtained my master's degree from the National Aerospace University in Kharkiv, Ukraine. My master's research centered around radio systems, with a focus on high-order spectrum techniques for signal processing, mentored by [Alexander Totsky](https://ieeexplore.ieee.org/author/37391220000).

We are always on the lookout for promising interns and full-time positions in the area of LLM and VLM efficiency. Feel free to reach out to me for more details. I am also interested in connecting with individuals who share similar research interests. -->


Pavlo Molchanov is a Distinguished Research Scientist and Team Manager at NVIDIA Research. Since 2023, he has been leading the [Deep Learning Efficiency Team](https://nv-dler.github.io) at [NVIDIA Research](https://www.nvidia.com/en-us/research/). He obtained a PhD from Tampere University of Technology, Finland, in 2014 with [Karen Eguiazarian](https://www.tuni.fi/en/karen-eguiazarian). During his studies, he received the Nokia Foundation Scholarship, GETA Graduate School grant, Best Paper Award, and Young Researcher Award at EuRAD. Recently, he has focused on efficiency in LLMs and multi-modal models: compression, NAS-like acceleration, novel architectures, and adaptive/conditional inference. 

His past research has led to several NVIDIA product integrations: hand, body, and facial keypoint estimation and recognition in [DriveIX](https://blogs.nvidia.com/blog/drive-ix-ecosystem/), [Broadcast](https://www.nvidia.com/en-us/geforce/broadcasting/broadcast-app/?ncid=pa-srch-goog-47075&gad_source=1&gclid=CjwKCAjwjqWzBhAqEiwAQmtgT_gPDTWhu4EQFQg4hmf5OqWMT7zWPvjnPAE7ZkicwT8NAHbT0ITyBBoCgEEQAvD_BwE#cid=gf45_pa-srch-goog_en-us), [Omniverse](https://www.nvidia.com/en-us/omniverse/), [Maxine](https://developer.nvidia.com/maxine); efficient vision backbones in [TAO](https://developer.nvidia.com/tao-toolkit), developed compression techniques in [TAO](https://developer.nvidia.com/tao-toolkit), [NVIDIA AV](https://developer.nvidia.com/drive), [TRT Model Optimization](https://github.com/NVIDIA/TensorRT-Model-Optimizer); and small in-game LLMs called [Minitron](https://nvidianews.nvidia.com/news/digital-humans-ace-generative-ai-microservices).

 We are always on the lookout for promising interns and full-time positions in the area of LLM and VLM efficiency. Feel free to reach out to me for more details. I am also interested in connecting with individuals who share similar research interests.

[comment]: <> ({{< icon name="download" pack="fas" >}} Download my {{< staticref "uploads/demo_resume.pdf" "newtab" >}}resum√©{{< /staticref >}}.)


<!-- Pavlo Molchanov is a Distinguished Research Scientist and Team Manager at NVIDIA Research since 2015. From 2023 he is leading the Deep Learning Efficiency Team. He obtained PhD from Tampere University of Technology, Finland in 2014. During his studies he received Nokia Foundation Scholarship, GETA Graduate School grant, Best Paper Award and Young Researcher Award at EuRAD. His areas of interest include efficient deep learning, human-centric computer vision, and signal processing. Recently he is focused on efficiency in LLMs and Multi-modal models: compression, NAS-like acceleration, novel architectures, and adaptive/conditional inference. His past research kicked-off a number of NVIDIA products: hand, body and facial keypoint estimation and recognition in NVIDIA DriveIX, NVIDIA Broadcast, NVIDIA Omniverse, NVIDIA Maxine; Efficient vision backbones NVIDIA TAO, developed compression techniques in NVIDIA TAO, NVIDIA AV, NVIDIA TRT Model Optimization. Currently he is contributing to NVIDIA LLMs (Nemo) and Vision-language models.  

DriveIX: https://blogs.nvidia.com/blog/drive-ix-ecosystem/


Foundational Vision Backbone Models and PEFT   -->


